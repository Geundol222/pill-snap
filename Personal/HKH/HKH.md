## ⚙️ 실험 환경
- **Baseline 모델**: YOLOv12s (Ultralytics)
- **데이터셋**: 알약 이미지 데이터 (pseudo-labeling + 보정 적용)
- **평가지표**: Validation mAP@[0.75:0.95]
- **하드웨어**: RTX 3070 (8GB VRAM)
- **프레임워크**: Ultralytics YOLO (v12), Python 3.12.10, CUDA 12.8

## ⚙️ 모델 실험

### 📌 가정
- **Epoch 수 증가** → 성능 상승 여부 확인  
- **Rotation을 에폭마다 다르게 적용** -> 성능 하락
- **TTA 적용** -> 성능 변화 X
- **YOLO 사이즈별 점수 비교** -> 사이즈가 커질수록 성능 상승

### 📊 결과

#### Epoch
- **10 epochs** : mAP@[0.75:0.95] = **0.74** 
- **30 epochs** : mAP@[0.75:0.95] = **0.83** 
- **50 epochs** : mAP@[0.75:0.95] = **0.83**

#### Rotation
| Params | Epochs | mAP@[0.50:0.95] |
|--------|--------|-----------------|
| rot*0.1epoches | 20 | 0.54 |

➡️ YOLO 기본 설정보다 성능 저하

#### TTA
| Epochs | 적용전 mAP@[0.75:0.95] | 적용후 mAP@[0.50:0.95] |
|--------|-----------------|-----------------|
| 5     | 0.82 | 0.82 | 
| 10     | 0.89 | 0.89 |
| 50     | 0.89 | 0.89 |

➡️ YOLO 기본 설정과 큰 차이 없음

| model size | epoches | mAP@[0.50:0.95] |
|--------|-----------------|-----------------|
| n     | 10 | 0.84 | 
| n     | 50 | 0.91 | 
| s     | 10 | 0.88 |
| s     | 50 | 0.92 |

➡️ m,l 모두 실험을 해보았으나 vram의 부족으로 결과 도출X

## 📝 결론

에폭 수의 증가를 통해 mAP의 상승을 확인하였으나 이는 명백하게 임계치가 존재하며 그 이후로는 노이즈에 따라 진동하는 모습을 보인다.
에폭 마다 rotation의 값에 변화를 주어 쉬운 변조부터 어려운 변조까지 모델에게 순차적인 학습을 하고자 하였으나 이는 오히려 모델의 성능을 떨어뜨리는 모습을 보인다.
이는 학습단계에서 낮은 단계의 이미지에서 거의 중복된 값을 주었기 때문에 이에 더 가중치를 두고 학습을 해버린 것이 문제가 아닐까라 생각하였습니다.
TTA적용을 통해 mAP의 상승을 도모하였으나, 모델의 시험 과정에서 별 다른 값을 내지 못함. 추가로 에폭 값에 따라 변동이 있을 수 있다고 생각하였으나, 결과는 동일.
YOLO 모델의 크기의 따라 mAP 점수의 차이를 확인 하였으나, 큰 모델로 갈수록 렘 사용량이 초과되어 실험이 불가(결과 도출을 위해 배치를 줄이고 nbs를 늘리는 선택을 하였으나 결과는 이또한 불가)