# 📌 실험 일지: 클래스 불균형 문제 해결 여정

## 1. 문제 정의 (Problem & Goal)

-   **문제:** EDA 결과, 우리 데이터셋은 최다/최소 클래스 간 샘플 수가 약 **73배** 차이 나는 극심한 **클래스 불균형** 상태임을 확인했습니다. 이로 인해 모델이 데이터가 적은 희귀 클래스를 제대로 학습하지 못하여, 전체 성능에 한계가 있을 것으로 예상됩니다.
-   **목표:** 희귀 클래스의 탐지 성능(Recall, AP)을 개선하여, 전체 mAP 점수를 안정적으로 향상시키는 최적의 전처리 전략을 찾습니다.

---

## 2. 실험 1: 단순 오버샘플링 (Image-level Oversampling)

### 가설
소수 클래스가 포함된 이미지 자체를 복제하여 데이터 수를 늘리면, 모델의 학습 기회가 늘어나 성능이 향상될 것이다.

### 실행 방법
1.  **대상 선정:** 데이터가 30개 미만인 클래스를 '소수 클래스'로 정의했습니다.
2.  **복제 실행:** 해당 클래스가 포함된 훈련용 이미지와 라벨 파일(.txt)을 통째로 복제하여, 모든 소수 클래스의 데이터 수를 최소 50개로 인위적으로 늘렸습니다.

### 결과 및 분석
-   **`mAP50-95`:** **0.8837**
-   **분석:** 기본 모델(mAP 약 0.875)과 비교했을 때, 통계적으로 유의미한 성능 향상이 없었습니다.
-   **실패 원인:** 우리 데이터는 이미지 한 장에 여러 객체가 포함되어 있습니다. 소수 클래스 이미지를 통째로 복제하자, 그 안에 있던 **다수 클래스까지 함께 증강**되어 불균형 해소 효과가 희석되었습니다. **이 방법은 우리 데이터셋에 부적합함**을 확인했습니다.

---

## 3. 실험 2: '스티커' 기법 (Offline Object Cropping)

### 가설
단순 오버샘플링의 단점을 보완하기 위해, 소수 클래스의 '객체'만 잘라내어(스티커) 별도의 훈련 데이터로 사용하면, 다수 클래스에 영향을 주지 않고 소수 클래스만 집중적으로 학습시킬 수 있을 것이다.

### 실행 방법
1.  **'스티커 북' 제작:** 소수 클래스 알약 객체만 Bbox 기준으로 잘라내어, 배경이 없는 개별 이미지 파일들을 모은 `_stickers` 폴더를 생성했습니다.
2.  **데이터셋 구성:** 기존 훈련 데이터와 '스티커' 데이터 폴더를 모두 훈련 경로에 포함시켜 모델을 학습시켰습니다.

### 결과 및 분석
-   **`mAP50-95`:** **약 0.771** (30 에포크 기준)
-   **분석:** 성능이 이전 베이스라인(~0.87)보다 오히려 **크게 하락**했습니다.
-   **실패 원인:** 이 방법은 모델에게 **두 개의 완전히 다른 세상(현실 vs. 가상)을 동시에 학습**시킨 것과 같습니다.
    -   **현실 세계:** 여러 알약이 복잡한 배경 위에 함께 있는 실제 이미지
    -   **가상 세계:** 알약 하나만 덩그러니 있는, **문맥(Context)이 제거된 '스티커' 이미지**
    모델은 이 두 이질적인 데이터 분포 사이에서 혼란을 겪었고, 실제 이미지에 대한 일반화 성능이 크게 저하되었습니다. 이 또한 **잘못된 접근 방식**임을 확인했습니다.

---

## 4. 종합 결론 및 다음 전략

### What Didn't Work
-   **단순 오버샘플링:** 다중 객체 환경에서 효과가 희석되어 실패.
-   **'스티커' 데이터 직접 학습:** 문맥이 제거된 인위적인 데이터가 모델 학습을 방해하여 실패.

### Lessons Learned
클래스 불균형을 해결하기 위해서는, **(1) 다수 클래스에 미치는 영향을 최소화**하면서 **(2) 실제 데이터의 문맥을 유지**하는, 더 정교한 방법이 필요합니다.

### Next Action (다음 실험 계획)
위 두 가지 실패를 바탕으로, 다음 두 가지 유력한 대안을 A/B 테스트하는 것이 가장 합리적입니다.

1.  **내장 Copy-Paste Augmentation:** YOLO 라이브러리가 제공하는 `copy_paste` 파라미터를 활성화합니다. 이는 '스티커'를 다른 **'실제 이미지'** 위에 실시간으로 붙여, 문맥을 유지하면서 데이터를 증강하는 방식입니다.
    ```python
    # 훈련 시 copy_paste 파라미터 추가
    results = model.train(copy_paste=0.1)
    ```
2.  **WeightedRandomSampler:** 파일을 직접 조작하지 않고, 훈련 시 **데이터를 뽑는 확률 자체를 조작**하여 소수 클래스가 더 자주 학습될 기회를 제공하는, 안정성이 검증된 방식입니다. (주로 커스텀 PyTorch 훈련 루프에 적용)